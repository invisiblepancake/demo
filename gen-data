#!/usr/bin/env python3
from __future__ import annotations

import argparse
import collections
import datetime
import json
import subprocess
import sys
import tempfile
import time
import urllib.request
import uuid
from typing import Any
from typing import Dict
from typing import List
from typing import NamedTuple
from typing import Tuple

REPO = 'pre-commit-ci-demo/demo'


def _parse_dt(s: str) -> datetime.datetime:
    assert s.endswith('Z'), s
    return datetime.datetime.fromisoformat(f'{s[:-1]}+00:00')


def _req(url: str, **kwargs: Any) -> Any:
    req = urllib.request.Request(url, **kwargs)
    return json.load(urllib.request.urlopen(req))


class Status(NamedTuple):
    created_at: datetime.datetime
    context: str
    description: str
    state: str

    @classmethod
    def make(cls, dct: Dict[str, Any]) -> Status:
        return cls(
            created_at=_parse_dt(dct['created_at']),
            context=dct['context'],
            description=dct['description'],
            state=dct['state'],
        )


class Check(NamedTuple):
    started_at: datetime.datetime
    completed_at: datetime.datetime
    name: str
    app: str
    status: str
    conclusion: str

    @classmethod
    def make(cls, dct: Dict[str, Any]) -> Check:
        return cls(
            started_at=_parse_dt(dct['started_at']),
            completed_at=_parse_dt(dct['completed_at']),
            name=dct['name'],
            app=dct['app']['slug'],
            status=dct['status'],
            conclusion=dct['conclusion'],
        )


class Run(NamedTuple):
    service: str
    seconds_to_start: int
    seconds_to_end: int


SERVICES = {
    # checks
    'Travis CI - Pull Request': 'travisci',
    'pre-commit': 'github',
    # statuses
    'ci/gitlab/gitlab.com': 'gitlab',
    'ci/circleci: build': 'circleci',
    'continuous-integration/appveyor/pr': 'appveyor',
    'pre-commit-ci-demo.demo': 'azurepipelines',
    'pre-commit.ci - pr': 'precommitci',
}
CHECKS_COUNT = 2
STATUSES_COUNT = len(SERVICES) - CHECKS_COUNT


def make_pr(headers: Dict[str, str]) -> Tuple[int, str]:
    with tempfile.TemporaryDirectory() as tmpdir:
        def _git(*cmd: str) -> None:
            subprocess.check_call(('git', '-C', tmpdir, *cmd))

        branch = f'pr-{uuid.uuid4().hex}'
        _git('clone', '--depth', '1', '--quiet', f'git@github.com:{REPO}', '.')
        _git('checkout', 'origin/HEAD', '-q', '-b', branch)
        _git('commit', '--allow-empty', '-q', '-m', 'test pr plz ignore')
        _git('push', 'origin', 'HEAD', '-q')

        upstream = subprocess.check_output((
            'git', '-C', tmpdir,
            'rev-parse', '--abbrev-ref', '--symbolic', '@{u}',
        ))
        target = upstream.strip().decode().split('/')[1]

    url = f'https://api.github.com/repos/{REPO}/pulls'
    data = {
        'title': 'test pr plz ignore',
        'body': f'generated by {sys.argv[0]}',
        'base': target,
        'head': branch,
    }
    data_b = json.dumps(data).encode()
    resp = _req(url, data=data_b, headers=headers, method='POST')
    return resp['number'], branch


def poll_for_results(pr: int, headers: Dict[str, str]) -> None:
    timeout = time.time() + 10 * 60

    base = 'https://api.github.com'
    pr_data = _req(f'{base}/repos/{REPO}/pulls/{pr}', headers=headers)
    sha = pr_data['head']['sha']
    print('zzz...')
    time.sleep(30)
    print('waiting for checks...')
    checks_url = f'{base}/repos/{REPO}/commits/{sha}/check-runs'
    while True:
        checks_data = _req(checks_url, headers=headers)
        done = [c for c in checks_data['check_runs'] if c['completed_at']]
        if len(done) >= CHECKS_COUNT:
            print(f'found {len(done)} checks!')
            break
        elif time.time() >= timeout:
            print('=> timeout')
            return
        else:
            print(f'=> waiting ({len(done)} completed)...')
            time.sleep(5)

    print('waiting for statuses...')
    while True:
        statuses_url = f'{base}/repos/{REPO}/commits/{sha}/status'
        statuses_data = _req(statuses_url, headers=headers)
        state = statuses_data['state']
        count = statuses_data['total_count']
        if state == 'success' and count == STATUSES_COUNT:
            print(f'found {statuses_data["total_count"]} statuses!')
            break
        elif time.time() >= timeout:
            print('=> timeout')
            return
        else:
            print(f'=> waiting ({state}: {count} reported)...')
            time.sleep(5)


def get_data(pr: int, headers: Dict[str, str]) -> List[Run]:
    base = 'https://api.github.com'
    pr_data = _req(f'{base}/repos/{REPO}/pulls/{pr}', headers=headers)
    sha = pr_data['head']['sha']
    statuses_url = f'{base}/repos/{REPO}/statuses/{sha}'
    statuses_data = _req(statuses_url, headers=headers)
    checks_url = f'{base}/repos/{REPO}/commits/{sha}/check-runs'
    checks_data = _req(checks_url, headers=headers)

    start_time = _parse_dt(pr_data['created_at'])
    statuses_by_context = collections.defaultdict(list)
    for dct in statuses_data:
        status = Status.make(dct)
        statuses_by_context[status.context].append(status)
    checks = [Check.make(dct) for dct in checks_data['check_runs']]

    runs = []
    for k, statuses in statuses_by_context.items():
        status_started = min(status.created_at for status in statuses)
        status_ended = max(status.created_at for status in statuses)
        run = Run(
            service=SERVICES[k],
            seconds_to_start=(status_started - start_time).seconds,
            seconds_to_end=(status_ended - start_time).seconds,
        )
        runs.append(run)

    for check in checks:
        run = Run(
            service=SERVICES[check.name],
            seconds_to_start=(check.started_at - start_time).seconds,
            seconds_to_end=(check.completed_at - start_time).seconds,
        )
        runs.append(run)

    runs.sort(key=lambda run: run.seconds_to_end)
    return runs


def delete_branch(branch: str, headers: Dict[str, str]) -> None:
    url = f'https://api.github.com/repos/{REPO}/git/refs/heads/{branch}'
    request = urllib.request.Request(url, headers=headers, method='DELETE')
    urllib.request.urlopen(request).read()


def main() -> int:
    parser = argparse.ArgumentParser()
    parser.parse_args()

    with open('.github-auth.json') as f:
        creds = json.load(f)
    headers = {'Authorization': f'token {creds["token"]}'}

    rows = []
    for _ in range(5):
        pr, branch = make_pr(headers)
        try:
            poll_for_results(pr, headers)
            results = get_data(pr, headers)
        finally:
            delete_branch(branch, headers)
        time.sleep(1)

        for result in results:
            rows.append((pr, *result))

    print('pr\tservice\tstart_time\trun_duration')
    for pr, service, start_time, end_time in rows:
        print(f'{pr}\t{service}\t{start_time}\t{end_time - start_time}')

    return 0


if __name__ == '__main__':
    exit(main())
